# ABA Therapy Team Scraper ğŸš€

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/) [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE) [![Build: pytest](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/laerciosimoes/aba-therapy-scraper/actions)

A versatile Python scraper that automates the discovery of "Team" pages on ABA therapy provider websites, extracts member details (Name, Position, Location) using LLM-driven pipelines, and consolidates everything into a single CSV for easy analysis.

## Table of Contents

- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Testing](#testing)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

## Features âœ¨

- **Contact Discovery**: Load or generate a CSV of provider contacts (Name, URL, Location).
- **Page Discovery**: Identify each providerâ€™s "Team" page URL.
- **LLMâ€‘Driven Scraping**: Use `SmartScraperGraph` and `SmartScraperMultiGraph` (ScrapeGraphAI) for robust link and content extraction.
- **Interim Outputs**: Store raw JSON per site for inspection and reprocessing.
- **Consolidation**: Merge all member records into **`final_team_members.csv` â€” Consolidated results**.
- **Unit Testing**: Builtâ€‘in pytest suite for core extraction logic.

## Prerequisites ğŸ› 

- **Python** 3.8+
- **Google Chrome** (for Selenium WebDriver)
- **ChromeDriver** matching your Chrome version
- **OpenAI API Key** (set in `.env`)

## Installation ğŸš€

1. **Clone the repo**:
   ```bash
   git clone https://github.com/laerciosimoes/aba-therapy-scraper.git
   cd aba-therapy-scraper
   ```
2. **Set up a virtual environment**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # macOS/Linux
   .\.venv\Scripts\activate  # Windows
   ```
3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
4. **Configure your environment**:
   ```bash
   cp .env.example .env
   # then edit .env to add your OPENAI_API_KEY
   ```

## Usage â–¶ï¸

1. Run the main script:
   ```bash
   python main.py
   ```
2. Check the `data/` folder for outputs:
   - `contacts_list.csv`      â€” Provider directory exports
   - `pages_list.csv`         â€” Detected "Team" page URLs
   - `team_members_<site>.json` â€” Raw JSON per site
   - **`final_team_members.csv` â€” Consolidated results**

## Project Structure ğŸ“‚

```plaintext
â”œâ”€â”€ main.py                     # Entry point with full workflow
â”œâ”€â”€ scrapper/
â”‚   â”œâ”€â”€ driverManager.py        # Selenium ChromeDriver manager
â”‚   â”œâ”€â”€ ABATherapyScraper.py    # Discovers team page URLs
â”‚   â””â”€â”€ TeamExtractor.py        # LLMâ€‘powered extraction logic
â”œâ”€â”€ data/                       # Input (contacts) & outputs (pages, JSON, CSV)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_team_extractor.py  # pytest suite for TeamExtractor
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Sample env file for API keys
â””â”€â”€ LICENSE                     # MIT License text
```

## Testing âœ…

Execute the pytest suite:
```bash
pytest tests/
```

## Roadmap ğŸ›£

- ğŸ”„ **Complete Coverage**: Loop through all 50 states (filter by state) to exhaustively capture providers.
- âš™ï¸ **Optimize Scraping**: Integrate more Selenium fallbacks to reduce LLM token usage and costs.
- ğŸŒ **Language Enforcement**: Force English extraction to avoid inconsistencies from nonâ€‘English pages.
- ğŸ’¡ **Retry Logic**: Add automated retries and backoff for transient failures.
- ğŸ“Š **Analytics Dashboard**: Provide a summary report or visual dashboard of extracted data.

## Contributing ğŸ¤

1. Fork the repo & create a branch: `git checkout -b feature/my-feature`
2. Commit your changes: `git commit -m "Add my feature"`
3. Push: `git push origin feature/my-feature`
4. Open a Pull Request.

Please follow the [code of conduct](CODE_OF_CONDUCT.md).

## License ğŸ“œ

Distributed under the MIT License. See [LICENSE](LICENSE) for details.

